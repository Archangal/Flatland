{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries, import data, prepare train/test split. Standard stuff."
      ],
      "metadata": {
        "id": "pU7ATUjLUbF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, Conv2D, BatchNormalization, \\\n",
        "                                    Activation, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import he_normal\n",
        "from tensorflow.image import pad_to_bounding_box\n",
        "from tensorflow.keras.layers import LayerNormalization"
      ],
      "metadata": {
        "id": "b_Apr70lWCH4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the NPZ file\n",
        "data = np.load('/flatland_train.npz')\n",
        "\n",
        "# Access the arrays in the NPZ file\n",
        "X = data['X']  # The input data (images)\n",
        "y = data['y']  # The corresponding labels\n",
        "\n",
        "y[y != 0] -= 2    # Correct labels so that triangle is mapped to class 1\n",
        "X = X / 255.      # Scale down to range [0, 1]\n",
        "\n",
        "# Optionally, if you want to close the file after loading\n",
        "data.close()"
      ],
      "metadata": {
        "id": "uODdGDbeWAoF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "9roRSE0QXP9S"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make copies of images from our train set by shifting them by a fixed amount of pixels in either direction: up, down, right or left. This is to account for shapes that are not fully contained in the image, and hopefully help the model learn shapes based on angle sizes"
      ],
      "metadata": {
        "id": "-XPEZEdUUorG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shift_amount = 10  # Adjust as needed\n",
        "\n",
        "# Create an empty array to store the shifted images\n",
        "X_train_shifted_right = np.zeros(X_train.shape)\n",
        "\n",
        "# Iterate through each image in X_train and apply the shift\n",
        "for i, image in enumerate(X_train):\n",
        "    # Shift the image to the right (positive direction)\n",
        "    shifted_image = np.roll(image, shift_amount, axis=1)\n",
        "\n",
        "    # Fill the empty spaces with black pixels (0)\n",
        "    if shift_amount > 0:\n",
        "        shifted_image[:, :shift_amount] = 0\n",
        "    elif shift_amount < 0:\n",
        "        shifted_image[:, shift_amount:] = 0\n",
        "\n",
        "    X_train_shifted_right[i] = shifted_image\n",
        "\n",
        "shift_amount = -10\n",
        "\n",
        "X_train_shifted_left = np.zeros(X_train.shape)\n",
        "\n",
        "# Iterate through each image in X_train and apply the shift\n",
        "for i, image in enumerate(X_train):\n",
        "    # Shift the image to the right (positive direction)\n",
        "    shifted_image = np.roll(image, shift_amount, axis=1)\n",
        "\n",
        "    # Fill the empty spaces with black pixels (0)\n",
        "    if shift_amount > 0:\n",
        "        shifted_image[:, :shift_amount] = 0\n",
        "    elif shift_amount < 0:\n",
        "        shifted_image[:, shift_amount:] = 0\n",
        "\n",
        "    X_train_shifted_left[i] = shifted_image\n",
        "\n",
        "shift_amount = 10\n",
        "\n",
        "X_train_shifted_up = np.zeros(X_train.shape)\n",
        "\n",
        "# Iterate through each image in X_train and apply the shift\n",
        "for i, image in enumerate(X_train):\n",
        "    # Shift the image upwards (positive direction)\n",
        "    shifted_image = np.roll(image, shift_amount, axis=0)\n",
        "\n",
        "    # Fill the empty spaces with black pixels (0)\n",
        "    if shift_amount > 0:\n",
        "        shifted_image[:shift_amount, :] = 0\n",
        "    elif shift_amount < 0:\n",
        "        shifted_image[shift_amount:, :] = 0\n",
        "\n",
        "    X_train_shifted_up[i] = shifted_image\n",
        "\n",
        "shift_amount = -10\n",
        "\n",
        "X_train_shifted_down = np.zeros(X_train.shape)\n",
        "\n",
        "# Iterate through each image in X_train and apply the shift\n",
        "for i, image in enumerate(X_train):\n",
        "    # Shift the image upwards (positive direction)\n",
        "    shifted_image = np.roll(image, shift_amount, axis=0)\n",
        "\n",
        "    # Fill the empty spaces with black pixels (0)\n",
        "    if shift_amount > 0:\n",
        "        shifted_image[:shift_amount, :] = 0\n",
        "    elif shift_amount < 0:\n",
        "        shifted_image[shift_amount:, :] = 0\n",
        "\n",
        "    X_train_shifted_down[i] = shifted_image"
      ],
      "metadata": {
        "id": "y1SRGItAwIrC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do the same but shift towards the corners: upleft, upright, downleft, downright"
      ],
      "metadata": {
        "id": "Iglz7h5wVFqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shift_amount = 10  # Adjust as needed\n",
        "\n",
        "# Create an empty array to store the shifted images\n",
        "X_train_shifted_upright = np.zeros(X_train.shape)\n",
        "\n",
        "# Iterate through each image in X_train and apply the shift\n",
        "for i, image in enumerate(X_train_shifted_up):\n",
        "    # Shift the image to the right (positive direction)\n",
        "    shifted_image = np.roll(image, shift_amount, axis=1)\n",
        "\n",
        "    # Fill the empty spaces with black pixels (0)\n",
        "    if shift_amount > 0:\n",
        "        shifted_image[:, :shift_amount] = 0\n",
        "    elif shift_amount < 0:\n",
        "        shifted_image[:, shift_amount:] = 0\n",
        "\n",
        "    X_train_shifted_upright[i] = shifted_image\n",
        "\n",
        "shift_amount = -10\n",
        "\n",
        "X_train_shifted_upleft = np.zeros(X_train.shape)\n",
        "\n",
        "# Iterate through each image in X_train and apply the shift\n",
        "for i, image in enumerate(X_train_shifted_up):\n",
        "    # Shift the image to the right (positive direction)\n",
        "    shifted_image = np.roll(image, shift_amount, axis=1)\n",
        "\n",
        "    # Fill the empty spaces with black pixels (0)\n",
        "    if shift_amount > 0:\n",
        "        shifted_image[:, :shift_amount] = 0\n",
        "    elif shift_amount < 0:\n",
        "        shifted_image[:, shift_amount:] = 0\n",
        "\n",
        "    X_train_shifted_upleft[i] = shifted_image\n",
        "\n",
        "shift_amount = 10  # Adjust as needed\n",
        "\n",
        "# Create an empty array to store the shifted images\n",
        "X_train_shifted_downright = np.zeros(X_train.shape)\n",
        "\n",
        "# Iterate through each image in X_train and apply the shift\n",
        "for i, image in enumerate(X_train_shifted_down):\n",
        "    # Shift the image to the right (positive direction)\n",
        "    shifted_image = np.roll(image, shift_amount, axis=1)\n",
        "\n",
        "    # Fill the empty spaces with black pixels (0)\n",
        "    if shift_amount > 0:\n",
        "        shifted_image[:, :shift_amount] = 0\n",
        "    elif shift_amount < 0:\n",
        "        shifted_image[:, shift_amount:] = 0\n",
        "\n",
        "    X_train_shifted_downright[i] = shifted_image\n",
        "\n",
        "shift_amount = -10\n",
        "\n",
        "X_train_shifted_downleft = np.zeros(X_train.shape)\n",
        "\n",
        "# Iterate through each image in X_train and apply the shift\n",
        "for i, image in enumerate(X_train_shifted_down):\n",
        "    # Shift the image to the right (positive direction)\n",
        "    shifted_image = np.roll(image, shift_amount, axis=1)\n",
        "\n",
        "    # Fill the empty spaces with black pixels (0)\n",
        "    if shift_amount > 0:\n",
        "        shifted_image[:, :shift_amount] = 0\n",
        "    elif shift_amount < 0:\n",
        "        shifted_image[:, shift_amount:] = 0\n",
        "\n",
        "    X_train_shifted_downleft[i] = shifted_image"
      ],
      "metadata": {
        "id": "kegEX25f-qlf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_negative = 1 - X_train"
      ],
      "metadata": {
        "id": "m5FkRsCImObI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expand our train sets by combining all the 9 versions of each image"
      ],
      "metadata": {
        "id": "KHaOVgSvVMTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate((X_train, X_train_shifted_up, X_train_shifted_down, X_train_shifted_right, X_train_shifted_left), axis=0)\n",
        "X_train = np.concatenate((X_train, X_train_shifted_upleft, X_train_shifted_downleft, X_train_shifted_upright, X_train_shifted_downright), axis=0)\n",
        "y_train = np.concatenate((y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train,), axis=0)"
      ],
      "metadata": {
        "id": "iA_UpYBxxsKL"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate((X_train, X_train_negative), axis=0)\n",
        "y_train = np.concatenate((y_train, y_train), axis=0)"
      ],
      "metadata": {
        "id": "_m66X3a6mujL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some vizualization:"
      ],
      "metadata": {
        "id": "ALHDRHTXVTZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = X_train[7002]\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Display the image\n",
        "ax.imshow(image, cmap='gray')\n",
        "\n",
        "# Remove axis labels and ticks\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "\n",
        "# Show the image\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "nJeqfrc6mtzq",
        "outputId": "dfa95da5-f18f-405b-9d7a-0fbfd402b6f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAI50lEQVR4nO3cPWgU7RrH4UkwGsFNsJGQD0sVxA/8SKOkELWOjXZCrATBQoIGewU/OlvBxkYrwdLWwsbORsEqkErRbBBUMHOalz+HlzOTPcvsrkmuq70zy13l5xOf2aGyLMsCAIqiGB70AgD8PUQBgBAFAEIUAAhRACBEAYAQBQBiRyc/tL6+XqysrBStVqsYGhrq9U4ANKwsy2Jtba2YnJwshoerzwMdRWFlZaWYmZlpbDkABmN5ebmYnp6unHf056NWq9XYQgAMzka/zzuKgj8ZAWwNG/0+9x/NAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCALFj0AsA1fbs2VM5O378eO2zp0+frpw9e/as9tnv37/Xztm6nBQACFEAIEQBgBAFAEIUAAhRACBcSYV/jIyMVM4OHDhQ++zJkye7mhVFUZw4caJyNjs7WznbuXNn7efWmZqaqp0vLi52/dlsbk4KAIQoABCiAECIAgAhCgCEKAAQogBADJVlWW70Q+12uxgfH+/HPmwTO3ZUvyJz8ODB2md79U7AqVOnKmejo6O1n7vZ/P79u3Z+5MiRytmnT5+aXoc+Wl1dLcbGxirnTgoAhCgAEKIAQIgCACEKAIQoABC+OpueuXjxYuXs1atXlbPdu3f3YBv+20Zfu/3gwYPK2aVLl5peh7+IkwIAIQoAhCgAEKIAQIgCACEKAIQoABDeU6BnDh06VDnzLsLfbX5+vnJ24cKFytmbN296sA395KQAQIgCACEKAIQoABCiAECIAgDhSio9Mz09PegV6IFHjx5Vzk6ePFn77J8/f5peh4Y5KQAQogBAiAIAIQoAhCgAEKIAQLiSSs/MzMwMegV64NixY5WzhYWF2mefPn3a9Do0zEkBgBAFAEIUAAhRACBEAYAQBQBCFAAI7ynQM746e/u5d+9e7fzly5eVs3a73fQ6dMFJAYAQBQBCFAAIUQAgRAGAEAUAwpVUesZXZ28/+/btq50vLS1Vzu7evdv0OnTBSQGAEAUAQhQACFEAIEQBgBAFAEIUAIihsizLjX6o3W4X4+Pj/diHTWR4uP7fFD9//qycjYyMNL0Om8CvX78qZ4cPH6599vPnz02vsy2trq4WY2NjlXMnBQBCFAAIUQAgRAGAEAUAQhQACF+dTdcmJiZq566d8m+7du2qnN2/f7/22StXrjS9Dv+DkwIAIQoAhCgAEKIAQIgCACEKAIQrqXRtZmZm0CuwhVy+fLl2/uTJk8rZ27dvm15n23JSACBEAYAQBQBCFAAIUQAgRAGAEAUAwnsKdG16enrQK7CFlGVZO5+amurTJtubkwIAIQoAhCgAEKIAQIgCACEKAIQrqXTNV2fTpNu3b9fOX7x40adNtjcnBQBCFAAIUQAgRAGAEAUAQhQACFEAILynQNe8p8D/6+HDh5Wzx48f93ETqjgpABCiAECIAgAhCgCEKAAQogBAuJJK11xJ5d+eP39eO19aWurTJnTLSQGAEAUAQhQACFEAIEQBgBAFAMKVVLr29evXQa/AALx+/bpytrCwUPtsWZZNr0PDnBQACFEAIEQBgBAFAEIUAAhRACBEAYAYKju4ONxut4vx8fF+7MMWcvTo0crZjRs3KmdXr16t/dzR0dGud6Iz7969q5ydP3++cvbjx49erEODVldXi7Gxscq5kwIAIQoAhCgAEKIAQIgCACEKAIQrqfx1JiYmaufXr1+vnN28ebP22b1793a101bz4cOH2vnc3Fzl7Nu3b02vQx+5kgpAx0QBgBAFAEIUAAhRACBEAYAQBQDCewpsKa1Wq3Z+7dq1ytmtW7cqZ/v37+96p0FZXl6unJ05c6brZ9ncvKcAQMdEAYAQBQBCFAAIUQAgRAGAcCUV/jEyMlI5m5+fr312cXGxcjY7O9vtSrW+fPlSOz979mzl7OPHj02vwybhSioAHRMFAEIUAAhRACBEAYAQBQDClVTosbqroUVRFHfu3Kmczc3NVc7OnTtX+7nv37+vX4xtyZVUADomCgCEKAAQogBAiAIAIQoAhCgAEN5TgL9Y3X3ydrvdx03YKrynAEDHRAGAEAUAQhQACFEAIEQBgNgx6AWAaq6d0m9OCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAdBSFsix7vQcAfbDR7/OOorC2ttbIMgAM1ka/z4fKDo4B6+vrxcrKStFqtYqhoaHGlgOgP8qyLNbW1orJyclieLj6PNBRFADYHvxHMwAhCgCEKAAQogBAiAIAIQoAhCgAEP8BEAgTLquOWiUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple CNN model is sufficient for this task. No fancy architecture"
      ],
      "metadata": {
        "id": "D-J84ybLVdAa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "U1Mm0_6aVQo1",
        "outputId": "58d45f03-09e2-4db9-cb7a-df28b32ffd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
            "                                                                 \n",
            " layer_normalization (Layer  (None, 48, 48, 32)        64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 24, 24, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 22, 64)        18496     \n",
            "                                                                 \n",
            " layer_normalization_1 (Lay  (None, 22, 22, 64)        128       \n",
            " erNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 11, 11, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " layer_normalization_2 (Lay  (None, 9, 9, 64)          128       \n",
            " erNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                65600     \n",
            "                                                                 \n",
            " layer_normalization_3 (Lay  (None, 64)                128       \n",
            " erNormalization)                                                \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " layer_normalization_4 (Lay  (None, 32)                64        \n",
            " erNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124266 (485.41 KB)\n",
            "Trainable params: 124266 (485.41 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# geriausias modelis so far\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(50, 50, 1)))\n",
        "model.add(LayerNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=Adam(learning_rate=3e-4),  # Adjust the learning rate as needed\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tiny model bandymas\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=(50, 50, 1)))\n",
        "model.add(LayerNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=Adam(learning_rate=3e-4),  # Adjust the learning rate as needed\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGDpIeHyBTfh",
        "outputId": "b39ef232-2734-4362-a481-288e4284bf58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_37 (Conv2D)          (None, 48, 48, 4)         40        \n",
            "                                                                 \n",
            " layer_normalization_57 (La  (None, 48, 48, 4)         8         \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPooli  (None, 24, 24, 4)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_57 (Dropout)        (None, 24, 24, 4)         0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 24, 24, 8)         296       \n",
            "                                                                 \n",
            " layer_normalization_58 (La  (None, 24, 24, 8)         16        \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPooli  (None, 12, 12, 8)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 12, 12, 8)         0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 12, 12, 16)        1168      \n",
            "                                                                 \n",
            " layer_normalization_59 (La  (None, 12, 12, 16)        32        \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPooli  (None, 6, 6, 16)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 6, 6, 16)          0         \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 6, 6, 32)          4640      \n",
            "                                                                 \n",
            " layer_normalization_60 (La  (None, 6, 6, 32)          64        \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPooli  (None, 3, 3, 32)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 3, 3, 32)          0         \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 288)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 32)                9248      \n",
            "                                                                 \n",
            " layer_normalization_61 (La  (None, 32)                64        \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " dropout_61 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " layer_normalization_62 (La  (None, 16)                32        \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16306 (63.70 KB)\n",
            "Trainable params: 16306 (63.70 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train our model until we reach satisfactory validation set accuracy"
      ],
      "metadata": {
        "id": "yeh7_gpwVq-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',     # The metric to monitor for improvement (e.g., validation loss)\n",
        "    patience=10,            # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True  # Restore model weights to the best observed during training\n",
        ")"
      ],
      "metadata": {
        "id": "zYSMgeKrXe-T"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.fit(X_train, y_train, epochs=100, validation_data=[X_test, y_test], callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ba7McBnIV0X1",
        "outputId": "0857739b-6392-415f-b453-078aa8c37e17"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2250/2250 [==============================] - 43s 13ms/step - loss: 0.8617 - accuracy: 0.6668 - val_loss: 0.1550 - val_accuracy: 0.9685\n",
            "Epoch 2/100\n",
            "2250/2250 [==============================] - 29s 13ms/step - loss: 0.1886 - accuracy: 0.9600 - val_loss: 0.1204 - val_accuracy: 0.9805\n",
            "Epoch 3/100\n",
            "2250/2250 [==============================] - 29s 13ms/step - loss: 0.1432 - accuracy: 0.9743 - val_loss: 0.1130 - val_accuracy: 0.9835\n",
            "Epoch 4/100\n",
            "2250/2250 [==============================] - 28s 13ms/step - loss: 0.1319 - accuracy: 0.9767 - val_loss: 0.1064 - val_accuracy: 0.9850\n",
            "Epoch 5/100\n",
            "2250/2250 [==============================] - 29s 13ms/step - loss: 0.1233 - accuracy: 0.9794 - val_loss: 0.1067 - val_accuracy: 0.9840\n",
            "Epoch 6/100\n",
            "2250/2250 [==============================] - 29s 13ms/step - loss: 0.1186 - accuracy: 0.9805 - val_loss: 0.1050 - val_accuracy: 0.9850\n",
            "Epoch 7/100\n",
            "2250/2250 [==============================] - 29s 13ms/step - loss: 0.1157 - accuracy: 0.9813 - val_loss: 0.1053 - val_accuracy: 0.9850\n",
            "Epoch 8/100\n",
            "2250/2250 [==============================] - 29s 13ms/step - loss: 0.1144 - accuracy: 0.9814 - val_loss: 0.1065 - val_accuracy: 0.9845\n",
            "Epoch 9/100\n",
            "2250/2250 [==============================] - 29s 13ms/step - loss: 0.1117 - accuracy: 0.9818 - val_loss: 0.1076 - val_accuracy: 0.9830\n",
            "Epoch 10/100\n",
            "2250/2250 [==============================] - 28s 13ms/step - loss: 0.1077 - accuracy: 0.9826 - val_loss: 0.1056 - val_accuracy: 0.9850\n",
            "Epoch 11/100\n",
            "2250/2250 [==============================] - 29s 13ms/step - loss: 0.1087 - accuracy: 0.9827 - val_loss: 0.1051 - val_accuracy: 0.9850\n",
            "Epoch 12/100\n",
            "2250/2250 [==============================] - 29s 13ms/step - loss: 0.1064 - accuracy: 0.9829 - val_loss: 0.1053 - val_accuracy: 0.9850\n",
            "Epoch 13/100\n",
            "2250/2250 [==============================] - 29s 13ms/step - loss: 0.1046 - accuracy: 0.9828 - val_loss: 0.1052 - val_accuracy: 0.9850\n",
            "Epoch 14/100\n",
            "2250/2250 [==============================] - 28s 13ms/step - loss: 0.1028 - accuracy: 0.9831 - val_loss: 0.1081 - val_accuracy: 0.9840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MgYYd7S8daba",
        "outputId": "e6738ee3-e77a-4022-bb16-d807d312b635"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 11ms/step - loss: 0.1064 - accuracy: 0.9850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.h5')\n",
        "from google.colab import files\n",
        "\n",
        "# Download the saved model file to your local machine\n",
        "files.download('my_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "h9Y26pCDdVYx",
        "outputId": "ea06dce4-2dd9-4fe7-8fe4-56d53cee7c1b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a934509d-60be-4d45-995d-6364af290da6\", \"my_model.h5\", 1590208)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}